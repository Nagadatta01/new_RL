"""
[1] EXPERIMENTAL SETUP AND BASELINE CONFIGURATION (2 Marks)
- Environment setup (state/action space, reward design)
- DQN model initialization
- Reproducibility with fixed seeds
"""

import torch
import numpy as np
from pathlib import Path
import json
from environment.realistic_delivery_env import RealisticDeliveryEnvironment
from models.dqn_agent import DQNAgent

SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)


def setup_baseline():
    """Setup baseline DQN configuration"""
    
    print("\n" + "="*80)
    print("[1] EXPERIMENTAL SETUP & BASELINE CONFIGURATION")
    print("="*80)
    
    # ===== ENVIRONMENT SETUP =====
    print("\nüìç ENVIRONMENT DEFINITION:")
    env = RealisticDeliveryEnvironment(grid_size=15, num_restaurants=3, num_customers=5)
    
    print(f"\n  ‚úì Environment Type: Custom Food Delivery")
    print(f"  ‚úì Grid Size: 15√ó15 cells")
    print(f"  ‚úì Restaurants: 3 (randomly placed)")
    print(f"  ‚úì Customers: 5 (randomly placed)")
    
    # STATE SPACE
    print(f"\n  üìä State Space (5D Vector):")
    print(f"     ‚Ä¢ agent_x: Agent X position (0-15)")
    print(f"     ‚Ä¢ agent_y: Agent Y position (0-15)")
    print(f"     ‚Ä¢ carrying: 0=empty, 1=carrying package")
    print(f"     ‚Ä¢ target_x: Target location X")
    print(f"     ‚Ä¢ target_y: Target location Y")
    print(f"     ‚Üí Total State Dimension: {int(env.state_dim)}")
    
    # ACTION SPACE
    print(f"\n  üéÆ Action Space (6 Discrete Actions):")
    print(f"     ‚Ä¢ Action 0: Move Up (y-1)")
    print(f"     ‚Ä¢ Action 1: Move Down (y+1)")
    print(f"     ‚Ä¢ Action 2: Move Left (x-1)")
    print(f"     ‚Ä¢ Action 3: Move Right (x+1)")
    print(f"     ‚Ä¢ Action 4: Pickup from Restaurant")
    print(f"     ‚Ä¢ Action 5: Delivery to Customer")
    print(f"     ‚Üí Total Action Dimension: {int(env.action_space.n)}")
    
    # REWARD STRUCTURE
    print(f"\n  üí∞ Reward Structure:")
    print(f"     ‚Ä¢ Movement Collision: -2.0 (hit obstacle)")
    print(f"     ‚Ä¢ Movement Normal: 0.0 (no reward)")
    print(f"     ‚Ä¢ Distance Shaping: (old_dist - new_dist) √ó 0.5")
    print(f"     ‚Ä¢ Pickup Success: +20.0")
    print(f"     ‚Ä¢ Delivery Success: +100.0")
    print(f"     ‚Ä¢ Episode Complete: +200.0 (all 5 delivered)")
    
    # ===== BASELINE DQN MODEL =====
    print(f"\nüß† BASELINE DQN MODEL INITIALIZATION:")
    
    baseline_config = {
        "learning_rate": 0.001,
        "gamma": 0.95,
        "epsilon_start": 1.0,
        "epsilon_end": 0.1,
        "epsilon_decay": 0.995,
        "buffer_size": 10000,
        "batch_size": 32,
        "target_update_freq": 100
    }
    
    agent = DQNAgent(
        state_dim=env.state_dim,
        action_dim=env.action_space.n,
        **baseline_config,
        device="cuda" if torch.cuda.is_available() else "cpu"
    )
    
    print(f"\n  ‚úì Network Architecture: 5 ‚Üí 128 ‚Üí 128 ‚Üí 128 ‚Üí 6")
    print(f"  ‚úì Optimizer: Adam")
    print(f"  ‚úì Loss Function: MSE (Mean Squared Error)")
    print(f"  ‚úì Device: {str(agent.device).upper()}")
    
    # ===== BASELINE HYPERPARAMETERS =====
    print(f"\n  üìã Baseline Hyperparameters:")
    for param, value in baseline_config.items():
        print(f"     ‚Ä¢ {param}: {value}")
    
    # ===== REPRODUCIBILITY =====
    print(f"\n‚úÖ REPRODUCIBILITY:")
    print(f"  ‚úì Random Seed (torch): {SEED}")
    print(f"  ‚úì Random Seed (numpy): {SEED}")
    print(f"  ‚úì All random operations are deterministic")
    
    # Save configuration - FIXED: Convert all to native Python types
    config_dir = Path("configs")
    config_dir.mkdir(exist_ok=True)
    
    config_data = {
        "environment": {
            "grid_size": int(15),
            "num_restaurants": int(3),
            "num_customers": int(5),
            "state_dim": int(env.state_dim),
            "action_dim": int(env.action_space.n),
            "max_steps_per_episode": int(env.max_steps)
        },
        "baseline_dqn": baseline_config,
        "seed": int(SEED),
        "device": str(agent.device)
    }
    
    with open(config_dir / "baseline_config.json", "w") as f:
        json.dump(config_data, f, indent=2)
    
    print(f"\n‚úì Configuration saved to: {config_dir}/baseline_config.json")
    print("\n" + "="*80 + "\n")
    
    return env, agent, baseline_config


if __name__ == "__main__":
    env, agent, config = setup_baseline()
    env.close()
